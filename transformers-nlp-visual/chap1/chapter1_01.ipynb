{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jWRCsjqGRMZL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this notebook is to show the overall computational time complexity.\n",
        "The self-attention = O(n^2*d), and recurrent is O(n*d^2)"
      ],
      "metadata": {
        "id": "Hv_zZvK2RR90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 512\n",
        "d = 512\n",
        "input_seq = np.random.rand(n,d)"
      ],
      "metadata": {
        "id": "6VBUjE39RgqT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simulation of self-attention layer\n",
        "start_time = time.time()\n",
        "for i in range(n):\n",
        "  for j in range(n):\n",
        "    _ = np.dot(input_seq[i],input_seq[j])\n",
        "at = time.time() - start_time\n",
        "print(f\"Self-attention computation time: {time.time() - start_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HktJyAqLRm9v",
        "outputId": "36542956-6f0f-405a-9393-24512ca50b7c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Self-attention computation time: 0.4317502975463867 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simulation of recurrent layer\n",
        "start_time = time.time()\n",
        "hidden_state = np.zeros(d)\n",
        "for i in range(n):\n",
        "  for j in range(n):\n",
        "    for k in range(d):\n",
        "      hidden_state[j] += input_seq[i,j] * hidden_state[k]\n",
        "rt = time.time() - start_time\n",
        "print(f\"Recurrent layer computation time: {time.time() - start_time} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja27hupSS3QR",
        "outputId": "b5447da4-384e-476a-ebdc-19ceb50062e1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recurrent layer computation time: 100.03673052787781 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can calcualte the percentage of the attention layer's comptuational time complexity and the recurrent layer's computational time complexitry."
      ],
      "metadata": {
        "id": "8lPSv3OyTv-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the total\n",
        "percentage_at = round( (at/(at+rt)) * 100,2)\n",
        "percentage_rt = round( (rt/(at+rt)) * 100,2)\n",
        "print(f\"The percentage of 'computation time for attention' in the sum of attention and recurrent is {percentage_at}\")\n",
        "print(f\"The percentage of 'computation time for recurrent' in the sum of attention and recurrent is {percentage_rt}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ryjn8CyT7rZ",
        "outputId": "e23e5cad-d367-4153-d621-07f60938f651"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The percentage of 'computation time for attention' in the sum of attention and recurrent is 0.43\n",
            "The percentage of 'computation time for recurrent' in the sum of attention and recurrent is 99.57\n"
          ]
        }
      ]
    }
  ]
}