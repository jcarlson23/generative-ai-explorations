{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to understand is what *convolution* means in the context of deep learning. \n",
    "\n",
    "Generally, a convolution is an integral that expresses the overlap of one function with another. So, it can be thought of *blending* two functions together. Or, another way of putting it is a convolution acts like a filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "input_layer = layers.Input(shape=(64,64,1))\n",
    "conv_layer_1 = layers.Conv2D( filters=2,\n",
    "                              kernel_size = (3,3),\n",
    "                              strides = 1,\n",
    "                              padding= \"same\")(input_layer)\n",
    "# *strides* is the step size used by the layer to move the filters across the input. \n",
    "# increasing the stride therefore reduces the size of the output tensor. For example,\n",
    "# if strides = 2, then the output tensor will be half the input tensor.\n",
    "\n",
    "# *padding* pads the input data with zeros so that the output size from the layer\n",
    "# so that the output size from the layer is the same size as it would be\n",
    "# if the *strides* parameter were set to 1.\n",
    "conv_layer_2 = layers.Conv2D(\n",
    "    filters = 20\n",
    "    , kernel_size = (3,3)\n",
    "    , strides = 2\n",
    "    , padding = 'same'\n",
    "    )(conv_layer_1)\n",
    "flatten_layer = layers.Flatten()(conv_layer_2)\n",
    "output_layer = layers.Dense(units=10, activation = 'softmax')(flatten_layer)\n",
    "model = models.Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model of the above network\n",
    "![Model of the Network](convolution_network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 64, 64, 2)         20        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 20)        380       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 20480)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                204810    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 205210 (801.60 KB)\n",
      "Trainable params: 205210 (801.60 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remember the point!\n",
    "Remember, that the whole point of this is that one of the reasons the network (from **mlp.ipynb**) isn’t yet performing as well as it might is because there isn’t anything in the network that takes into account the spatial structure of the input images. In fact, the first step is to flatten the image into a single vector, so that we can pass it to the first Dense layer!\n",
    "\n",
    "So the convolution filters function to blend adjacent pixles so that we can vectorize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Batch Normalization\n",
    "\n",
    "One of the more common problems when training a deep neural network is ensuring that the weights of the network reamin within a reasonable range of values -- if they become too large, this is a sign that the network is suffering as the *exploding gradient* problem, meaning the the weight values can fluctuate wildly.\n",
    "\n",
    "##### Warning \n",
    "If the loss function returns a NaN at any point, chances are that the weights have grown too large, and caused an overflow.\n",
    "\n",
    "So what is the root casuse of an exploding gradient?\n",
    "\n",
    "The technical term here is covariate shift, but perhaps a more plain term might cumulative shift. In that if we scale the input, say going from pixel values of 0-255 -> -1 to 1, that seems fine for the input layer, but over time subsequent layers might also shift. We get this cumulative shift in weights that can result in an exploding gradient (essentially the neural network is overcorrecting because it's become too sensitive per layer, and not flexible enough as a whole).\n",
    "\n",
    "**Batch normalization** solves this by inserting a layer -- a batch normalization layer -- that normalizes all of its inputs. From the text:\n",
    "\n",
    "During training, a batch normalization layer calculates the mean and standard deviation of each of its input channels across the batch and normalizes by subtracting the mean and dividing by the standard deviation. There are then two learned parameters for each channel, the scale (gamma) and shift (beta). \n",
    "\n",
    "Essentially, it's smoothing out the preceding input layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropouts\n",
    "\n",
    "Dropouts are simply a way of forcing some weights to be reset to fight against over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "input_layer = layers.Input((32,32,3))\n",
    "\n",
    "x = layers.Conv2D(filters = 32, kernel_size = 3\n",
    "\t, strides = 1, padding = 'same')(input_layer)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(filters = 32, kernel_size = 3, strides = 2, padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(filters = 64, kernel_size = 3, strides = 2, padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(128)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Dropout(rate = 0.5)(x)\n",
    "\n",
    "output_layer = layers.Dense(10, activation = 'softmax')(x)\n",
    "\n",
    "model = models.Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32, 32, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 16, 16, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 8, 8, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               524416    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 592554 (2.26 MB)\n",
      "Trainable params: 591914 (2.26 MB)\n",
      "Non-trainable params: 640 (2.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bring back our previous example and see how this convolusion Neural Network now performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import datasets, utils\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test  = x_test.astype('float32') / 255.0\n",
    "\n",
    "y_train = utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test  = utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 1.5627 - accuracy: 0.4546\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 1.1487 - accuracy: 0.5952\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 1.0000 - accuracy: 0.6495\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.9149 - accuracy: 0.6820\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.8620 - accuracy: 0.6998\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.8112 - accuracy: 0.7187\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.7650 - accuracy: 0.7341\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.7194 - accuracy: 0.7515\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.6892 - accuracy: 0.7583\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.6598 - accuracy: 0.7694\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 0.8271 - accuracy: 0.7193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8270503878593445, 0.7192999720573425]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "opt = optimizers.Adam(learning_rate=0.0005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "### Training the Model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size= 32,\n",
    "          epochs = 10,\n",
    "          shuffle = True)\n",
    "model.evaluate(x_test, y_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vast improvement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's investigate\n",
    "Let's try again, without batch normalization (and then without drop outs).. Just to see the potential issues occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 1.4619 - accuracy: 0.4817\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 1.1139 - accuracy: 0.6083\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.9732 - accuracy: 0.6575\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 24s 16ms/step - loss: 0.8843 - accuracy: 0.6918\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.8209 - accuracy: 0.7109\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.7695 - accuracy: 0.7300\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.7242 - accuracy: 0.7435\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.6789 - accuracy: 0.7608\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.6440 - accuracy: 0.7719\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.6083 - accuracy: 0.7851\n",
      "10/10 [==============================] - 1s 81ms/step - loss: 0.8936 - accuracy: 0.7057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8935840129852295, 0.7056999802589417]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer = layers.Input((32,32,3))\n",
    "\n",
    "x = layers.Conv2D(filters = 32, kernel_size = 3\n",
    "\t, strides = 1, padding = 'same')(input_layer)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(filters = 32, kernel_size = 3, strides = 2, padding = 'same')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(filters = 64, kernel_size = 3, strides = 2, padding = 'same')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(128)(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Dropout(rate = 0.5)(x)\n",
    "\n",
    "output_layer = layers.Dense(10, activation = 'softmax')(x)\n",
    "\n",
    "model = models.Model(input_layer, output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "### Training the Model\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size= 32,\n",
    "          epochs = 10,\n",
    "          shuffle = True)\n",
    "model.evaluate(x_test, y_test, batch_size=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
